{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logo.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 10]\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Análisis de Componentes Principales (PCA)\n",
    "\n",
    "En este notebook vamos a ver en primer lugar el algoritmo PCA de forma \"manual\", es decir, haremos los pasos uno por uno. Posteriormente veremos como usar la implementación de `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Ejemplo 1: \n",
    "\n",
    "En este ejemplo manual vamos a usar el dataset de flores Iris, y aplicaremos PCA para reducir su dimensionalidad de 3 a 2 dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar el endpoint de matplotlib notebook para poder modificar la orientación de un gráfico en 3d de las 3 dimensiones del dataset que vamos a utilizar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D #es necesario importar esto para que se pueda usar la proyección 3d\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel(\"longitud sépalo\", size=20)\n",
    "ax.set_ylabel(\"anchura sépalo\", size=20)\n",
    "ax.set_zlabel(\"longitud pétalo\", size=20)\n",
    "ax.scatter(iris.data[:,0], iris.data[:,1], iris.data[:,2], c=iris.target,\n",
    "           cmap=cm.prism)\n",
    "ax.view_init(20, 120)\n",
    "plt.show()\n",
    "\n",
    "def actualizar_grafica(angulo1=20, angulo2=120):\n",
    "    # Cambiamos el ángulo de la visualización\n",
    "    ax.view_init(angulo1, angulo2)\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# widgets\n",
    "angulo1_slider = widgets.IntSlider(20, min = 0, max = 90)\n",
    "display(angulo1_slider)\n",
    "\n",
    "def actualizar_angulo1(value):\n",
    "    actualizar_grafica(angulo1=value['new'])\n",
    "\n",
    "angulo1_slider.observe(actualizar_angulo1, names='value');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 1 de PCA. Centrar los datos. \n",
    "\n",
    "Este paso consiste en restar a cada dimension (cada variable) su media. Vamos a eliminar la 4 variable del dataset para reducir de 3 dimensiones a 2 y poder hacerlo de forma gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_centrado = (iris.data - iris.data.mean(axis=0))[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_centrado[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2. Calcular la matriz de covarianza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la formula para la varianza y covarianza. Si se le pasa dos muestras devuelve la covarianza entre ambas variables, si se le pasa 1 devuelve la varianza de dicha variable.\n",
    "\n",
    "Dado que generalmente vamos a trabajar con muestras (nunca con poblaciones completas) al calcular la varianza se divide la suma total de diferencias cuadraticas por N-1 en vez de por N. Esto se llama [Corrección de Bessel](https://es.wikipedia.org/wiki/Correcci%C3%B3n_de_Bessel) y se utiliza al calcular la desviación estandard o la varianza de una muestra para corregir el sesgo (bias) intrínseco de calcular estadísticos descriptivos tomando solo una porción de la población total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varianza(var1, var2=None):\n",
    "    if var2 is None:\n",
    "        var2 = var1\n",
    "    assert var1.shape== var2.shape\n",
    "    var1_mean = var1.mean()\n",
    "    var2_mean = var2.mean()\n",
    "    return  np.sum((var1-var1_mean)*(var2-var2_mean)) / (var1.shape[0] -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = np.array([5,10,17,35])\n",
    "var2 = np.array([34,70, 75,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varianza(var1, var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varianza(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varianza(var2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vez de calcular la varianza con nuestra función podemos usar la función de numpy `np.cov`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(np.array([var1, var2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos ahora la matriz de covarianza de los datos centrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat = np.cov(m=iris_centrado.T)\n",
    "cov_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3. Descomponer matriz de covarianza\n",
    "Ahora falta usar un método de álgebra lineal para obtener los vectores propios de dicha matriz de covarianza. Para ello podemos usar `np.linalg.eig` que descompone una matriz en sus vectores propios (eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linalg.eig.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_propios, vec_propios = np.linalg.eig(cov_mat)\n",
    "\n",
    "print('Vectores Propios:\\n', vec_propios)\n",
    "print('\\nValores Propios:', val_propios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los componentes principales son las columnas de la matriz de vectores propios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OJO!**, en la implementación de `numpy.linalg.eig` los valores propios no estan ordenados de mayor a menor. Vemos que el valor propio 2 (el segundo en terminos de varianza) está en tercera posición en el vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asi que podemos tomar los componentes principales y ordenarlos en función de la varianza explicada de cada uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(val_propios)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orden_componentes = np.argsort(val_propios)[::-1]\n",
    "val_propios_ordenados = val_propios[orden_componentes]\n",
    "\n",
    "vec_propios_ordenados = vec_propios[:,orden_componentes]\n",
    "\n",
    "print('Vectores Propios (ordenados):\\n', vec_propios_ordenados)\n",
    "print('\\nValores Propios (ordenados):', val_propios_ordenados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los vectores propios son las coordenadas de los 3 vectores propios de la matriz de covarianza, es decir, los 3 componentes principales. Los 3 valores propios son la varianza que se explica mediante cada uno de los 3 componentes principales. Vemos que el primer componente es el más importante con diferencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a hacer la misma gráfica en 3d, pero mostrando los componentes principales. Para mostrarlos como flechas, he copiado la implementación de [esta respuesta en StackOverflow](https://stackoverflow.com/a/22867877/1403840), donde se muestra una implementación de las flechas de matplotlib que funcionan en 3d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "class Arrow3D(FancyArrowPatch):\n",
    "    def __init__(self, xs, ys, zs, *args, **kwargs):\n",
    "        FancyArrowPatch.__init__(self, (0,0), (0,0), *args, **kwargs)\n",
    "        self._verts3d = xs, ys, zs\n",
    "\n",
    "    def draw(self, renderer):\n",
    "        xs3d, ys3d, zs3d = self._verts3d\n",
    "        xs, ys, zs = proj3d.proj_transform(xs3d, ys3d, zs3d, renderer.M)\n",
    "        self.set_positions((xs[0],ys[0]),(xs[1],ys[1]))\n",
    "        FancyArrowPatch.draw(self, renderer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los origenes de los componentes principales son las medias de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# las medias del dataset centrado son el origen de los componentes principales\n",
    "media_x = iris_centrado[:,0].mean()\n",
    "media_y = iris_centrado[:,1].mean()\n",
    "media_z = iris_centrado[:,2].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel(\"eje X\", size=20)\n",
    "ax.set_ylabel(\"eje Y\", size=20)\n",
    "ax.set_zlabel(\"eje Z\", size=20)\n",
    "\n",
    "ax.scatter(iris_centrado[:,0], iris_centrado[:,1], iris_centrado[:,2], c=iris.target,\n",
    "           cmap=cm.prism)\n",
    "\n",
    "for v in vec_propios:\n",
    "    \n",
    "    a = Arrow3D([media_x, v[0]], [media_y, v[1]], \n",
    "                [media_z, v[2]], mutation_scale=20, \n",
    "                lw=3, arrowstyle=\"-|>\", color=\"r\")\n",
    "    ax.add_artist(a)\n",
    "    #ax.plot([media_x, v[0]], [media_y, v[1]], [media_z, v[2]], color='red', alpha=0.8, lw=3)\n",
    "ax.view_init(20, 120)\n",
    "\n",
    "\n",
    "def actualizar_grafica(angulo1=20, angulo2=120):\n",
    "    # Cambiamos el ángulo de la visualización\n",
    "    ax.view_init(angulo1, angulo2)\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# widgets\n",
    "angulo1_slider = widgets.IntSlider(20, min = 0, max = 90)\n",
    "display(angulo1_slider)\n",
    "\n",
    "def actualizar_angulo1(value):\n",
    "    actualizar_grafica(angulo1=value['new'])\n",
    "\n",
    "angulo1_slider.observe(actualizar_angulo1, names = 'value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora para transformar puntos en el nuevo sistema de coordenadas de los componentes principales simplemente tenemos que multiplicar dichos puntos por el número de componentes principales que queramos considerar. \n",
    "\n",
    "#### ¿Cuantos componentes seleccionar?\n",
    "\n",
    "En cuanto al número de componentes que elegir, podemos seguir ciertas reglas de sentido común:\n",
    "- Elegir al menos componentes que sumen el 80% de la varianza total\n",
    "- Elegir aquellos componentes con una varianza explicada mayor que la media\n",
    "- Realizar un gráfico de los valores propios de cada componente de forma decreciente y usar el método del codo para ver en que momento hay ganancias decrecientes de los componentes principales (esto se llama gráfica *SCREE*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_propios_ordenados)\n",
    "plt.title(\"Gráfica SCREE de componentes principales\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver el porcentaje de varianza que explica cada componente principal sumando los valores propios de cada vector propio y dividiendo por la suma total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "PCA 1: {0:.2f}% de la varianza\n",
    "PCA 2:  {1:.2f}% de la varianza\n",
    "PCA 3:  {2:.2f}% de la varianza\n",
    "\"\"\".format(*tuple(val_propios_ordenados / val_propios_ordenados.sum() * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, si queremos reducir el dataset de 3 dimensiones a 2, simplemente tenemos que tomar los dos primeros componentes principales (definidos como las columnas de la matriz de vectores propios)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_propios_ordenados[:,:2].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora solo tenemos que hacer un producto de los datos con los componentes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_coord_princ = iris_centrado @ vec_propios_ordenados[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_coord_princ[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "plt.scatter(iris_coord_princ[:,0], iris_coord_princ[:,1], c=iris.target, \n",
    "            cmap=cm.Set3)\n",
    "plt.title(\"Dataset Iris descompuesto en sus 2 primeros componentes principales\", size=18)\n",
    "plt.xlabel(\"Componente Principal 1\", size=18)\n",
    "plt.ylabel(\"Componente Principal 2\", size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vemos como usar PCA en sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "iris_pca = pca.fit_transform(iris_centrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los componentes principales asi como su varianza explicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en este caso el resultado de scikitlearn produce componentes principales con el sentido cambiado respecto a nuestra implementación \"manual\". Diversos métodos numéricos pueden producir los vectores en distinta orientación, esto no afecta al resultado (es decir, a la separación de los puntos en cuanto a su varianza)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_propios[:,[0,2]].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_pca[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "plt.scatter(iris_pca[:,0], iris_pca[:,1], c=iris.target, \n",
    "            cmap=cm.Set3)\n",
    "plt.title(\"Dataset Iris descompuesto en sus 2 primeros componentes principales (scikit-learn)\", size=18)\n",
    "plt.xlabel(\"Componente Principal 1\", size=18)\n",
    "plt.ylabel(\"Componente Principal 2\", size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo 2\n",
    "\n",
    "\n",
    "En este ejemplo vamos a hacer la implementación de scikit learn con escalado.\n",
    "\n",
    "Vamos a usar el dataset del cancer de mama (Breast Cancer dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar cargamos los datos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente, tenemos que sustraerles la media, esto podemos hacerlo simplemente usando `sklearn.preprocessing.StandardScaler`, (recordad, el estandarizado resta la media y divide por la desviación estándar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalador = StandardScaler()\n",
    "scalador.fit(cancer.data)\n",
    "cancer_escalado = scalador.transform(cancer.data)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(cancer_escalado)\n",
    "\n",
    "cancer_pca = pca.transform(cancer_escalado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "plt.scatter(cancer_pca[:, 0], cancer_pca[:, 1], c=cancer.target, cmap=cm.Set3)\n",
    "plt.title(\"Dataset Cáncer de mama 2 primeros componentes principales\", size=18)\n",
    "plt.xlabel(\"Componente Principal 1\", size=18)\n",
    "plt.ylabel(\"Componente Principal 2\", size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Vemos como reducir la dimensionalidad de 30 dimensiones a 2 componentes principales nos vale para separar la mayor parte de los cánceres en benignos y malignos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
