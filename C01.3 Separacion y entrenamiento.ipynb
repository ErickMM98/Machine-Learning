{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separación y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "boston.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(objetivo, estimaciones):\n",
    "    return np.sqrt(metrics.mean_squared_error(objetivo, estimaciones)\n",
    "                  )\n",
    "\n",
    "def adjusted_r2(objetivo, estimaciones, n, k):\n",
    "    r2 = metrics.r2_score(objetivo, estimaciones)\n",
    "    return 1 - (1-r2)*(n-1) / (n - k - 1)\n",
    "\n",
    "def evaluar_modelo(objetivo, estimaciones, n, k):\n",
    "    return {\n",
    "        \"rmse\": rmse(objetivo, estimaciones),\n",
    "        \"mae\": metrics.mean_absolute_error(objetivo, estimaciones),\n",
    "        \"adjusted_r2\": adjusted_r2(objetivo, estimaciones, n, k)\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_ols = LinearRegression()\n",
    "\n",
    "modelo_ols.fit(X=boston[\"data\"], y=boston[\"target\"])\n",
    "\n",
    "modelo_ols_preds = modelo_ols.predict(boston[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTADOS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = boston[\"data\"].shape[0]\n",
    "\n",
    "RESULTADOS[\"ols\"] = evaluar_modelo(\n",
    "    boston[\"target\"],\n",
    "    modelo_ols_preds,\n",
    "    N,\n",
    "    len(modelo_ols.coef_)\n",
    ")\n",
    "\n",
    "RESULTADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta este momento hemos usado todos los datos como entrenamiento, de modo que posiblemente tengamos problemas de sobreajuste y por lo tanto tengamos errores si introducimos datos nuevos. Lo que haremos entonces es dividir la tabla para reentrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     boston[\"data\"], boston[\"target\"],\n",
    "     test_size=0.33, random_state=13\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos el modelo\n",
    "modelo_ols = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo entrenándolo\n",
    "modelo_ols.fit(X=X_train, y=y_train)\n",
    "modelo_ols_train_preds = modelo_ols.predict(X_train)\n",
    "\n",
    "# Obtenemos los resultados del modelo recién entrenado\n",
    "RESULTADOS[\"ols_train\"] = evaluar_modelo(\n",
    "    y_train,\n",
    "    modelo_ols_train_preds,\n",
    "    X_train.shape[0],\n",
    "    len(modelo_ols.coef_)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta este momento, los coeficientes de la regresión en el modelo entrenado están guardados en ``modelo_ols.intercept_`` y ``modelo_ols.coef_``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"intercepcion\":modelo_ols.intercept_,\"coeficientes\":modelo_ols.coef_}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando estos parámetros, aplicamos a ``X_test``, el conjunto de prueba, para obtener las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_ols_test_preds = modelo_ols.predict(X_test)\n",
    "\n",
    "RESULTADOS[\"ols_test\"] = evaluar_modelo(\n",
    "    y_test,\n",
    "    modelo_ols_test_preds,\n",
    "    X_test.shape[0],\n",
    "    len(modelo_ols.coef_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(RESULTADOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que al separar los datos de entrenamiento y los de test se obtiene un resultado peor al evaluar los datos de train.\n",
    "\n",
    "Podríamos parar aquí y decir *\"El error RMSE de mi modelo es 4.787026\"*, y podríamos pensar que esta todo bien ya que no hemos entrenado el modelo en los datos que hemos usado para evaluarlo.\n",
    "\n",
    "Pero estaríamos en un grave error. ¿Por qué? \n",
    "\n",
    "Recordemos que hemos usado un `random_state=13` para la función `train_test_split` que garantiza que la separación de entrenamiento y test sea siempre la misma. Podemos usar cualquier número para este argumento.\n",
    "\n",
    "Qué pasa si usamos por ejemplo `random_state=42`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTADOS = {}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     boston[\"data\"], boston[\"target\"],\n",
    "     test_size=0.33, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "modelo_ols = LinearRegression()\n",
    "modelo_ols.fit(X=X_train, y=y_train)\n",
    "modelo_ols_train_preds = modelo_ols.predict(X_train)\n",
    "modelo_ols_test_preds = modelo_ols.predict(X_test)\n",
    "\n",
    "\n",
    "RESULTADOS[\"ols_train\"] = evaluar_modelo(\n",
    "    y_train,\n",
    "    modelo_ols_train_preds,\n",
    "    X_train.shape[0],\n",
    "    len(modelo_ols.coef_)\n",
    ")\n",
    "\n",
    "RESULTADOS[\"ols_test\"] = evaluar_modelo(\n",
    "    y_test,\n",
    "    modelo_ols_test_preds,\n",
    "    X_test.shape[0],\n",
    "    len(modelo_ols.coef_)\n",
    ")\n",
    "\n",
    "\n",
    "pd.DataFrame(RESULTADOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡El error en los datos de test es menor que en los de entrenamiento! ¿Por qué? Sencillamente, por que ha dado la casualidad de que hemos separado los datos de una forma que los datos de test son muy fáciles de estimar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver la magnitud del error en el que estamos cayendo al hacer una sola separación entre test y entrenamiento, vamos a probar un monton de semillas y ver cual es el rango del error que se puede obtener "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LinearRegression()\n",
    "results = []\n",
    "def test_seed(seed):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "     boston[\"data\"], boston[\"target\"],\n",
    "     test_size=0.33, random_state=seed\n",
    "    )\n",
    "    test_preds = model.fit(X_train, y_train).predict(X_test)\n",
    "    seed_rmse = rmse(y_test, test_preds)\n",
    "    results.append([seed_rmse, seed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    test_seed(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sorted = sorted(results, key=lambda x: x[0], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sorted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sorted[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validación Cruzada (Cross Validation)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que entre la semilla con menor error de test y la semilla con mayor error hay una diferencia casi del doble!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una forma de evitar el cometer este error es mediante la **Validación cruzada**\n",
    "\n",
    "![cross_val](https://cdn-images-1.medium.com/max/1600/1*J2B_bcbd1-s1kpWOu_FZrg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_ols = LinearRegression()\n",
    "X = boston[\"data\"]\n",
    "y = boston[\"target\"]\n",
    "\n",
    "resultados_validación_cruzada = cross_val_score(\n",
    "    estimator=modelo_ols, \n",
    "    X=X,\n",
    "    y=y,\n",
    "    scoring=\"neg_mean_squared_error\", \n",
    "    cv=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_validación_cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_validación_cruzada.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cross_val(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return np.sqrt(metrics.mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_cv = []\n",
    "for i in range(10,200):\n",
    "    cv_rmse = cross_val_score(\n",
    "        estimator=modelo_ols, \n",
    "        X=X,\n",
    "        y=y,\n",
    "        scoring=rmse_cross_val, \n",
    "        cv=i\n",
    "    ).mean()\n",
    "    resultados_cv.append(cv_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(resultados_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scoring = {\"mae\": \"neg_mean_absolute_error\", \"rmse\": rmse_cross_val}\n",
    "estimator = modelo_ols\n",
    "scores = cross_validate(estimator, boston[\"data\"],\n",
    "                        boston[\"target\"], scoring=scoring,\n",
    "                         cv=100, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
