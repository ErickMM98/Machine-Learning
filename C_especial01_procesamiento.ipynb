{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logo.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers</th>\n",
       "      <th>col_outliers2</th>\n",
       "      <th>col_categorica</th>\n",
       "      <th>col_ordinal</th>\n",
       "      <th>col_texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.232832</td>\n",
       "      <td>-50</td>\n",
       "      <td>0.771666</td>\n",
       "      <td>ratón</td>\n",
       "      <td>muy bien</td>\n",
       "      <td>Tenía en su casa una ama que pasaba de los cua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.906147</td>\n",
       "      <td>-5</td>\n",
       "      <td>1.068558</td>\n",
       "      <td>elefante</td>\n",
       "      <td>regular</td>\n",
       "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.626750</td>\n",
       "      <td>-32</td>\n",
       "      <td>0.846396</td>\n",
       "      <td>ratón</td>\n",
       "      <td>muy mal</td>\n",
       "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.816738</td>\n",
       "      <td>-84</td>\n",
       "      <td>0.637381</td>\n",
       "      <td>gato</td>\n",
       "      <td>mal</td>\n",
       "      <td>Una olla de algo más vaca que carnero, salpicó...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.571131</td>\n",
       "      <td>65</td>\n",
       "      <td>4.540614</td>\n",
       "      <td>gato</td>\n",
       "      <td>bien</td>\n",
       "      <td>Tenía en su casa una ama que pasaba de los cua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_inexistente1  col2      col3  col_outliers  col_outliers2  \\\n",
       "0              59.0  52.0  2.232832           -50       0.771666   \n",
       "1              31.0  74.0  0.906147            -5       1.068558   \n",
       "2              81.0  28.0  0.626750           -32       0.846396   \n",
       "3              34.0  16.0  0.816738           -84       0.637381   \n",
       "4              32.0  28.0  0.571131            65       4.540614   \n",
       "\n",
       "  col_categorica col_ordinal  \\\n",
       "0          ratón    muy bien   \n",
       "1       elefante     regular   \n",
       "2          ratón     muy mal   \n",
       "3           gato         mal   \n",
       "4           gato        bien   \n",
       "\n",
       "                                           col_texto  \n",
       "0  Tenía en su casa una ama que pasaba de los cua...  \n",
       "1  El resto della concluían sayo de velarte, calz...  \n",
       "2  El resto della concluían sayo de velarte, calz...  \n",
       "3  Una olla de algo más vaca que carnero, salpicó...  \n",
       "4  Tenía en su casa una ama que pasaba de los cua...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = pd.read_csv(\"datos_procesamiento.csv\")\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_inexistente1    float64\n",
       "col2                float64\n",
       "col3                float64\n",
       "col_outliers          int64\n",
       "col_outliers2       float64\n",
       "col_categorica       object\n",
       "col_ordinal          object\n",
       "col_texto            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables Numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputación de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_inexistente1    float64\n",
       "col2                float64\n",
       "col3                float64\n",
       "col_outliers          int64\n",
       "col_outliers2       float64\n",
       "col_categorica       object\n",
       "col_ordinal          object\n",
       "col_texto            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp master\\.conda\\envs\\scidata\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['col_inexistente1', 'col2', 'col3', 'col_outliers2', 'col_outliers'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df = datos.select_dtypes([int, float])\n",
    "var_numericas_df[\"col_outliers\"] = datos[\"col_outliers\"]\n",
    "var_numericas_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df[var_numericas_df.isnull().any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers2</th>\n",
       "      <th>col_outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.270999</td>\n",
       "      <td>1.067230</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.394209</td>\n",
       "      <td>4.145716</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.437365</td>\n",
       "      <td>20.549474</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.324893</td>\n",
       "      <td>0.761684</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3.664671</td>\n",
       "      <td>3.154153</td>\n",
       "      <td>-48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    col_inexistente1  col2      col3  col_outliers2  col_outliers\n",
       "9                NaN  53.0  2.270999       1.067230            62\n",
       "10               NaN  99.0  1.394209       4.145716            98\n",
       "16               NaN  50.0  0.437365      20.549474            59\n",
       "17               NaN  73.0  0.324893       0.761684            98\n",
       "23               NaN  85.0  3.664671       3.154153           -48"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df[var_numericas_df.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputador = SimpleImputer(missing_values=np.nan, copy=False, strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_numericas_imputadas = imputador.fit_transform(var_numericas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59.        ,  52.        ,   2.23283208,   0.77166646,\n",
       "        -50.        ],\n",
       "       [ 31.        ,  74.        ,   0.90614714,   1.06855838,\n",
       "         -5.        ],\n",
       "       [ 81.        ,  28.        ,   0.62675042,   0.84639576,\n",
       "        -32.        ],\n",
       "       ...,\n",
       "       [ 19.        ,  53.        ,   0.73723413,   1.34525201,\n",
       "         73.        ],\n",
       "       [ 88.        ,  94.        ,   0.76008706,   1.3692463 ,\n",
       "         68.        ],\n",
       "       [ 94.        ,  56.        ,   1.2299403 ,   0.94395714,\n",
       "         61.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers2</th>\n",
       "      <th>col_outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.232832</td>\n",
       "      <td>0.771666</td>\n",
       "      <td>-50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.906147</td>\n",
       "      <td>1.068558</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.626750</td>\n",
       "      <td>0.846396</td>\n",
       "      <td>-32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.816738</td>\n",
       "      <td>0.637381</td>\n",
       "      <td>-84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.571131</td>\n",
       "      <td>4.540614</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.618844</td>\n",
       "      <td>0.812940</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.167880</td>\n",
       "      <td>1.235137</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.229813</td>\n",
       "      <td>1.283176</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.407978</td>\n",
       "      <td>1.298613</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48.382743</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.270999</td>\n",
       "      <td>1.067230</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_inexistente1  col2       col3  col_outliers2  col_outliers\n",
       "0         59.000000  52.0   2.232832       0.771666         -50.0\n",
       "1         31.000000  74.0   0.906147       1.068558          -5.0\n",
       "2         81.000000  28.0   0.626750       0.846396         -32.0\n",
       "3         34.000000  16.0   0.816738       0.637381         -84.0\n",
       "4         32.000000  28.0   0.571131       4.540614          65.0\n",
       "5         81.000000   4.0   1.618844       0.812940          51.0\n",
       "6         57.000000  31.0   0.167880       1.235137          78.0\n",
       "7         34.000000  20.0  20.229813       1.283176          93.0\n",
       "8         37.000000  96.0   2.407978       1.298613          54.0\n",
       "9         48.382743  53.0   2.270999       1.067230          62.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_df = pd.DataFrame(var_numericas_imputadas,\n",
    "                                                   index=var_numericas_df.index,\n",
    "                                                   columns=var_numericas_df.columns)\n",
    "\n",
    "var_numericas_imputadas_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_df[var_numericas_imputadas_df.isnull().any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estandarización**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de Estandarización es un proceso requerido por una gran cantidad de modelos en Scikit-learn. El objetivo es obtener una variable con media 0 y desviación estándar 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['col_inexistente1', 'col2', 'col3', 'col_outliers2', 'col_outliers'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_inexistente1     48.382743\n",
       "col2                 49.660000\n",
       "col3                  1.466095\n",
       "col_outliers2       131.193340\n",
       "col_outliers          4.253000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col_inexistente1      27.987174\n",
       "col2                  28.272668\n",
       "col3                   1.732358\n",
       "col_outliers2       3401.164776\n",
       "col_outliers          78.145901\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello el transformador mas sencillo en sklearn es [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador = preprocessing.StandardScaler()\n",
    "var_numericas_imputadas_escalado_standard = escalador.fit_transform(var_numericas_imputadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 48.38274336,  49.66      ,   1.46609489, 131.19333968,\n",
       "         4.253     ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "escalador.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.86197757e-17,  1.26121336e-16, -3.81916720e-17, -3.55271368e-18,\n",
       "        3.55271368e-18])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_standard.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_standard.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39921733,  0.08280686,  0.44281884, -0.03836537, -0.69460006])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_standard[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aquellos casos en los que los datos tengan muchos valores extremos, es posible que estandarizar usando la media y la desviacion estandar no funcione bien en el modelo. Para esos casos es mejor usar unos estimadores mas robustos (menos sensibles a outliers) y emplear un [RobustScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler) que funciona substrayendo la mediana y escalando mediante el rango intercuartil (IQR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador_robusto = preprocessing.RobustScaler()\n",
    "var_numericas_imputadas_escalado_robusto = escalador_robusto.fit_transform(\n",
    "                                                        var_numericas_imputadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.81916720e-17, -2.85106383e-02,  4.01958704e-01,  7.03130782e+01,\n",
       "        3.04018692e-02])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_robusto.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.33218559e-01, 6.01245275e-01, 1.38651621e+00, 1.83690817e+03,\n",
       "       7.29970260e-01])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_robusto.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escalado a un rango especifico**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay casos en los que en vez de estandardizar queremos escalar los datos a un rango (generalmente [-1,1] o [0,1]). Para ello podemos usar [MinMaxScaler](scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler) que hace escalado minmax (obviamente) o [MaxAbscaler](scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbscaler) que simplemente divide cada valor de una variable por su valor máximo (y por tanto convierte el valor maximo a 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-100.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107357.85777352"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador_minmax = preprocessing.MinMaxScaler()\n",
    "var_numericas_imputadas_escalado_minmax = escalador_minmax.fit_transform(var_numericas_imputadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_minmax.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_minmax.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador_maxabs = preprocessing.MaxAbsScaler()\n",
    "var_numericas_imputadas_escalado_maxabs = escalador_maxabs.fit_transform(var_numericas_imputadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_maxabs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1122334455667789"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_escalado_maxabs.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Hay casos en los que lo que se necesita es tener observaciones con norma unitaria (norma L2 o euclidiana). Para esos casos, podemos usar [Normalizer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = preprocessing.Normalizer()\n",
    "var_numericas_imputadas_normal = normalizador.fit_transform(var_numericas_imputadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que el objetivo del Normalizer es normalizar casos, no variables (o sea que funciona por filas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38557802,  0.92041204,  0.01127066,  0.01329073, -0.06219   ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_numericas_imputadas_normal[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(var_numericas_imputadas_normal[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Variables Categoricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos están diseñados para trabajar con variables numéricas. Esto implica que para poder entrenar los modelos con variables categóricas tenemos que convertirlas a números. Este proceso se llama *codificación (encoding)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers</th>\n",
       "      <th>col_outliers2</th>\n",
       "      <th>col_categorica</th>\n",
       "      <th>col_ordinal</th>\n",
       "      <th>col_texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.232832</td>\n",
       "      <td>-50</td>\n",
       "      <td>0.771666</td>\n",
       "      <td>ratón</td>\n",
       "      <td>muy bien</td>\n",
       "      <td>Tenía en su casa una ama que pasaba de los cua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.906147</td>\n",
       "      <td>-5</td>\n",
       "      <td>1.068558</td>\n",
       "      <td>elefante</td>\n",
       "      <td>regular</td>\n",
       "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.626750</td>\n",
       "      <td>-32</td>\n",
       "      <td>0.846396</td>\n",
       "      <td>ratón</td>\n",
       "      <td>muy mal</td>\n",
       "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.816738</td>\n",
       "      <td>-84</td>\n",
       "      <td>0.637381</td>\n",
       "      <td>gato</td>\n",
       "      <td>mal</td>\n",
       "      <td>Una olla de algo más vaca que carnero, salpicó...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.571131</td>\n",
       "      <td>65</td>\n",
       "      <td>4.540614</td>\n",
       "      <td>gato</td>\n",
       "      <td>bien</td>\n",
       "      <td>Tenía en su casa una ama que pasaba de los cua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_inexistente1  col2      col3  col_outliers  col_outliers2  \\\n",
       "0              59.0  52.0  2.232832           -50       0.771666   \n",
       "1              31.0  74.0  0.906147            -5       1.068558   \n",
       "2              81.0  28.0  0.626750           -32       0.846396   \n",
       "3              34.0  16.0  0.816738           -84       0.637381   \n",
       "4              32.0  28.0  0.571131            65       4.540614   \n",
       "\n",
       "  col_categorica col_ordinal  \\\n",
       "0          ratón    muy bien   \n",
       "1       elefante     regular   \n",
       "2          ratón     muy mal   \n",
       "3           gato         mal   \n",
       "4           gato        bien   \n",
       "\n",
       "                                           col_texto  \n",
       "0  Tenía en su casa una ama que pasaba de los cua...  \n",
       "1  El resto della concluían sayo de velarte, calz...  \n",
       "2  El resto della concluían sayo de velarte, calz...  \n",
       "3  Una olla de algo más vaca que carnero, salpicó...  \n",
       "4  Tenía en su casa una ama que pasaba de los cua...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = pd.read_csv(\"datos_procesamiento.csv\")\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_categoricas = datos[['col_categorica', 'col_ordinal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_categorica</th>\n",
       "      <th>col_ordinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ratón</td>\n",
       "      <td>muy bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elefante</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ratón</td>\n",
       "      <td>muy mal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gato</td>\n",
       "      <td>mal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gato</td>\n",
       "      <td>bien</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col_categorica col_ordinal\n",
       "0          ratón    muy bien\n",
       "1       elefante     regular\n",
       "2          ratón     muy mal\n",
       "3           gato         mal\n",
       "4           gato        bien"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_categoricas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay muchas formas de codificar variables, la más sencilla es reemplazar los elementos de dichas variables por un número. Por ejemplo, si hacemos esto con la columna `col_ordinal`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador = preprocessing.LabelEncoder()\n",
    "label_codificador.fit(datos.col_ordinal) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bien', 'mal', 'muy bien', 'muy mal', 'regular'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador.transform(['muy bien', 'muy mal', 'muy bien', 'muy mal', 'bien'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bien', 'bien', 'mal', 'muy bien'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador.inverse_transform([0, 0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de variables ordinales esto tiene sentido ya que `muy_bien>bien>regular>mal>muy mal`. Sin embargo, esto indica a los modelos de scikit-learn por ejemplo que `mal + regular = bien`. Esto se puede usar en según que casos (hay modelos que no interpretan las variables numéricas así), o para codificar las variables objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para variables categóricas (por ejemplo animales) no tiene sentido usar este tipo de encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, 1, 1, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador_categorico = preprocessing.LabelEncoder()\n",
    "label_codificador_categorico.fit_transform(datos.col_categorica)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['elefante', 'gato', 'perro', 'ratón'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador_categorico.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digamos que no tiene sentido decir que la media de `elefante` y `perro` no es `gato`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Para estos casos una técnica que se puede usar se llama `one-hot encoding`. Lo que significa es que creamos n columnas binarias, con el valor 0 por defecto salvo la columna referente a la observación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esto podemos usar \n",
    "[OneHotEncoder](scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_codificador = preprocessing.OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['ratón' 'elefante' 'ratón' 'gato' 'gato' 'perro' 'perro' 'perro'\n 'elefante' 'elefante' 'perro' 'elefante' 'gato' 'ratón' 'gato' 'ratón'\n 'elefante' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'ratón' 'gato'\n 'gato' 'ratón' 'gato' 'elefante' 'gato' 'elefante' 'elefante' 'elefante'\n 'elefante' 'ratón' 'elefante' 'gato' 'elefante' 'gato' 'gato' 'gato'\n 'gato' 'ratón' 'elefante' 'gato' 'gato' 'perro' 'elefante' 'gato'\n 'elefante' 'perro' 'ratón' 'perro' 'elefante' 'ratón' 'ratón' 'gato'\n 'gato' 'elefante' 'ratón' 'perro' 'gato' 'gato' 'gato' 'gato' 'ratón'\n 'elefante' 'elefante' 'perro' 'gato' 'ratón' 'perro' 'elefante' 'gato'\n 'gato' 'ratón' 'ratón' 'elefante' 'perro' 'ratón' 'ratón' 'elefante'\n 'gato' 'perro' 'ratón' 'gato' 'elefante' 'elefante' 'perro' 'perro'\n 'perro' 'ratón' 'gato' 'ratón' 'gato' 'gato' 'elefante' 'gato' 'gato'\n 'perro' 'perro' 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'perro' 'gato'\n 'gato' 'ratón' 'gato' 'perro' 'perro' 'perro' 'gato' 'perro' 'perro'\n 'elefante' 'perro' 'ratón' 'gato' 'gato' 'gato' 'gato' 'ratón' 'ratón'\n 'ratón' 'perro' 'elefante' 'elefante' 'perro' 'ratón' 'gato' 'elefante'\n 'gato' 'ratón' 'ratón' 'elefante' 'gato' 'perro' 'ratón' 'gato'\n 'elefante' 'elefante' 'elefante' 'elefante' 'perro' 'elefante' 'elefante'\n 'gato' 'ratón' 'perro' 'perro' 'gato' 'perro' 'perro' 'elefante' 'gato'\n 'perro' 'perro' 'perro' 'perro' 'gato' 'ratón' 'gato' 'gato' 'gato'\n 'perro' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'elefante' 'elefante'\n 'ratón' 'elefante' 'elefante' 'elefante' 'ratón' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'gato' 'gato' 'perro' 'elefante' 'elefante'\n 'elefante' 'ratón' 'perro' 'perro' 'gato' 'ratón' 'gato' 'perro' 'ratón'\n 'elefante' 'ratón' 'ratón' 'gato' 'ratón' 'gato' 'ratón' 'elefante'\n 'gato' 'gato' 'perro' 'elefante' 'perro' 'perro' 'gato' 'elefante'\n 'elefante' 'elefante' 'gato' 'perro' 'gato' 'perro' 'elefante' 'elefante'\n 'elefante' 'elefante' 'perro' 'gato' 'gato' 'elefante' 'ratón' 'perro'\n 'perro' 'ratón' 'ratón' 'perro' 'perro' 'elefante' 'elefante' 'perro'\n 'gato' 'perro' 'ratón' 'perro' 'ratón' 'gato' 'ratón' 'perro' 'elefante'\n 'gato' 'gato' 'ratón' 'ratón' 'perro' 'gato' 'ratón' 'ratón' 'perro'\n 'elefante' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'elefante' 'perro'\n 'ratón' 'perro' 'perro' 'perro' 'ratón' 'ratón' 'ratón' 'perro'\n 'elefante' 'perro' 'elefante' 'gato' 'elefante' 'elefante' 'elefante'\n 'elefante' 'ratón' 'elefante' 'ratón' 'elefante' 'perro' 'ratón' 'gato'\n 'elefante' 'perro' 'perro' 'ratón' 'perro' 'ratón' 'gato' 'gato' 'perro'\n 'gato' 'ratón' 'perro' 'elefante' 'gato' 'perro' 'gato' 'elefante'\n 'perro' 'ratón' 'gato' 'perro' 'elefante' 'elefante' 'gato' 'ratón'\n 'gato' 'elefante' 'perro' 'perro' 'ratón' 'gato' 'ratón' 'gato' 'perro'\n 'gato' 'perro' 'ratón' 'ratón' 'perro' 'ratón' 'gato' 'gato' 'ratón'\n 'ratón' 'gato' 'perro' 'elefante' 'elefante' 'gato' 'ratón' 'gato'\n 'ratón' 'gato' 'ratón' 'elefante' 'ratón' 'ratón' 'elefante' 'elefante'\n 'gato' 'elefante' 'ratón' 'elefante' 'perro' 'elefante' 'elefante'\n 'perro' 'gato' 'gato' 'elefante' 'perro' 'perro' 'perro' 'perro' 'gato'\n 'perro' 'ratón' 'ratón' 'gato' 'elefante' 'gato' 'gato' 'perro' 'ratón'\n 'perro' 'perro' 'elefante' 'ratón' 'ratón' 'gato' 'perro' 'perro'\n 'elefante' 'gato' 'perro' 'gato' 'gato' 'ratón' 'ratón' 'gato' 'perro'\n 'gato' 'ratón' 'perro' 'perro' 'ratón' 'gato' 'perro' 'perro' 'gato'\n 'gato' 'perro' 'elefante' 'ratón' 'ratón' 'perro' 'elefante' 'elefante'\n 'gato' 'ratón' 'elefante' 'perro' 'ratón' 'elefante' 'perro' 'perro'\n 'gato' 'elefante' 'elefante' 'elefante' 'ratón' 'perro' 'gato' 'gato'\n 'ratón' 'ratón' 'ratón' 'perro' 'elefante' 'gato' 'gato' 'gato' 'perro'\n 'elefante' 'gato' 'elefante' 'elefante' 'elefante' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'elefante' 'ratón' 'elefante' 'perro' 'ratón'\n 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'gato' 'ratón' 'perro' 'perro'\n 'ratón' 'gato' 'elefante' 'perro' 'gato' 'gato' 'ratón' 'elefante'\n 'ratón' 'ratón' 'ratón' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'ratón' 'perro' 'ratón' 'ratón' 'perro' 'perro' 'gato' 'perro' 'ratón'\n 'perro' 'elefante' 'ratón' 'elefante' 'gato' 'perro' 'gato' 'elefante'\n 'ratón' 'perro' 'perro' 'gato' 'perro' 'gato' 'gato' 'perro' 'gato'\n 'elefante' 'elefante' 'ratón' 'ratón' 'gato' 'gato' 'gato' 'perro'\n 'elefante' 'gato' 'ratón' 'elefante' 'elefante' 'ratón' 'ratón' 'perro'\n 'gato' 'gato' 'elefante' 'elefante' 'ratón' 'elefante' 'gato' 'ratón'\n 'gato' 'gato' 'ratón' 'perro' 'ratón' 'elefante' 'ratón' 'elefante'\n 'gato' 'gato' 'gato' 'gato' 'perro' 'gato' 'gato' 'ratón' 'perro'\n 'elefante' 'gato' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'elefante' 'ratón' 'perro' 'gato' 'perro' 'perro' 'perro' 'perro' 'gato'\n 'ratón' 'gato' 'elefante' 'perro' 'gato' 'perro' 'ratón' 'ratón' 'perro'\n 'elefante' 'elefante' 'elefante' 'perro' 'perro' 'ratón' 'perro' 'perro'\n 'ratón' 'ratón' 'ratón' 'gato' 'perro' 'gato' 'gato' 'ratón' 'ratón'\n 'gato' 'perro' 'gato' 'ratón' 'perro' 'perro' 'perro' 'ratón' 'ratón'\n 'ratón' 'elefante' 'gato' 'gato' 'elefante' 'gato' 'gato' 'ratón' 'ratón'\n 'ratón' 'perro' 'perro' 'elefante' 'elefante' 'elefante' 'elefante'\n 'elefante' 'perro' 'ratón' 'ratón' 'ratón' 'gato' 'ratón' 'gato' 'gato'\n 'elefante' 'elefante' 'elefante' 'perro' 'ratón' 'perro' 'perro' 'perro'\n 'gato' 'ratón' 'elefante' 'perro' 'elefante' 'elefante' 'elefante'\n 'elefante' 'elefante' 'perro' 'elefante' 'perro' 'ratón' 'elefante'\n 'elefante' 'perro' 'gato' 'ratón' 'ratón' 'elefante' 'elefante' 'gato'\n 'ratón' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'perro' 'perro'\n 'perro' 'elefante' 'elefante' 'elefante' 'gato' 'ratón' 'elefante'\n 'ratón' 'gato' 'perro' 'gato' 'elefante' 'gato' 'ratón' 'gato' 'gato'\n 'elefante' 'gato' 'gato' 'elefante' 'perro' 'perro' 'gato' 'perro' 'gato'\n 'ratón' 'gato' 'ratón' 'perro' 'perro' 'ratón' 'elefante' 'perro' 'perro'\n 'gato' 'perro' 'gato' 'perro' 'elefante' 'ratón' 'elefante' 'perro'\n 'perro' 'gato' 'perro' 'perro' 'gato' 'ratón' 'gato' 'gato' 'elefante'\n 'gato' 'perro' 'gato' 'gato' 'perro' 'gato' 'ratón' 'ratón' 'perro'\n 'gato' 'gato' 'elefante' 'ratón' 'perro' 'elefante' 'elefante' 'ratón'\n 'ratón' 'perro' 'gato' 'perro' 'ratón' 'gato' 'gato' 'perro' 'perro'\n 'perro' 'gato' 'perro' 'elefante' 'elefante' 'perro' 'perro' 'elefante'\n 'ratón' 'gato' 'ratón' 'gato' 'elefante' 'elefante' 'perro' 'ratón'\n 'gato' 'elefante' 'perro' 'perro' 'gato' 'gato' 'ratón' 'perro' 'perro'\n 'ratón' 'perro' 'ratón' 'gato' 'perro' 'elefante' 'ratón' 'ratón' 'perro'\n 'gato' 'perro' 'perro' 'perro' 'elefante' 'perro' 'gato' 'ratón' 'ratón'\n 'perro' 'ratón' 'gato' 'gato' 'ratón' 'perro' 'ratón' 'ratón' 'perro'\n 'elefante' 'gato' 'ratón' 'elefante' 'elefante' 'perro' 'gato' 'perro'\n 'perro' 'gato' 'ratón' 'perro' 'ratón' 'gato' 'ratón' 'elefante'\n 'elefante' 'perro' 'elefante' 'perro' 'gato' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'ratón' 'elefante' 'ratón' 'elefante' 'elefante'\n 'ratón' 'perro' 'perro' 'perro' 'elefante' 'ratón' 'gato' 'gato' 'gato'\n 'perro' 'elefante' 'elefante' 'elefante' 'gato' 'elefante' 'perro' 'gato'\n 'elefante' 'elefante' 'ratón' 'gato' 'gato' 'ratón' 'perro' 'elefante'\n 'perro' 'perro' 'perro' 'elefante' 'perro' 'perro' 'elefante' 'perro'\n 'elefante' 'gato' 'elefante' 'gato' 'gato' 'perro' 'gato' 'ratón'\n 'elefante' 'perro' 'perro' 'perro' 'elefante' 'perro' 'ratón' 'gato'\n 'elefante' 'gato' 'ratón' 'gato' 'gato' 'ratón' 'elefante' 'gato'\n 'elefante' 'elefante' 'gato' 'perro' 'gato' 'elefante' 'perro' 'ratón'\n 'elefante' 'elefante' 'elefante' 'elefante' 'perro' 'ratón' 'perro'\n 'ratón' 'gato' 'elefante' 'ratón' 'ratón' 'perro' 'elefante' 'ratón'\n 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'ratón' 'gato' 'gato'\n 'elefante' 'perro' 'elefante' 'perro' 'gato' 'perro' 'perro' 'perro'\n 'perro' 'ratón' 'ratón' 'gato' 'perro' 'gato' 'elefante' 'perro' 'ratón'\n 'perro' 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'gato' 'perro' 'ratón'\n 'perro' 'elefante' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'ratón' 'perro' 'gato' 'gato' 'gato' 'perro' 'ratón' 'perro' 'ratón'\n 'elefante' 'perro' 'perro' 'ratón' 'elefante' 'ratón' 'elefante' 'ratón'\n 'gato' 'gato' 'gato' 'perro' 'elefante' 'gato' 'perro' 'gato' 'ratón'\n 'ratón' 'gato' 'elefante' 'gato' 'elefante' 'elefante' 'gato' 'ratón'\n 'ratón' 'ratón' 'gato' 'elefante' 'perro' 'perro' 'elefante' 'ratón'\n 'perro' 'elefante' 'ratón' 'gato' 'perro' 'ratón' 'gato' 'gato' 'ratón'\n 'ratón' 'gato' 'perro' 'perro' 'perro' 'elefante' 'gato' 'ratón' 'ratón'\n 'elefante' 'ratón' 'elefante' 'elefante' 'elefante'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-c3430f1a49b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moh_codificador\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol_categorica\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\scidata\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \"\"\"\n\u001b[0;32m    384\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_idx_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_drop_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scidata\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, handle_unknown)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mX_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scidata\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'iloc'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# if not a dataframe, do normal check_array validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mX_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             if (not hasattr(X, 'dtype')\n\u001b[0;32m     45\u001b[0m                     and np.issubdtype(X_temp.dtype, np.str_)):\n",
      "\u001b[1;32m~\\.conda\\envs\\scidata\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scidata\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    621\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['ratón' 'elefante' 'ratón' 'gato' 'gato' 'perro' 'perro' 'perro'\n 'elefante' 'elefante' 'perro' 'elefante' 'gato' 'ratón' 'gato' 'ratón'\n 'elefante' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'ratón' 'gato'\n 'gato' 'ratón' 'gato' 'elefante' 'gato' 'elefante' 'elefante' 'elefante'\n 'elefante' 'ratón' 'elefante' 'gato' 'elefante' 'gato' 'gato' 'gato'\n 'gato' 'ratón' 'elefante' 'gato' 'gato' 'perro' 'elefante' 'gato'\n 'elefante' 'perro' 'ratón' 'perro' 'elefante' 'ratón' 'ratón' 'gato'\n 'gato' 'elefante' 'ratón' 'perro' 'gato' 'gato' 'gato' 'gato' 'ratón'\n 'elefante' 'elefante' 'perro' 'gato' 'ratón' 'perro' 'elefante' 'gato'\n 'gato' 'ratón' 'ratón' 'elefante' 'perro' 'ratón' 'ratón' 'elefante'\n 'gato' 'perro' 'ratón' 'gato' 'elefante' 'elefante' 'perro' 'perro'\n 'perro' 'ratón' 'gato' 'ratón' 'gato' 'gato' 'elefante' 'gato' 'gato'\n 'perro' 'perro' 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'perro' 'gato'\n 'gato' 'ratón' 'gato' 'perro' 'perro' 'perro' 'gato' 'perro' 'perro'\n 'elefante' 'perro' 'ratón' 'gato' 'gato' 'gato' 'gato' 'ratón' 'ratón'\n 'ratón' 'perro' 'elefante' 'elefante' 'perro' 'ratón' 'gato' 'elefante'\n 'gato' 'ratón' 'ratón' 'elefante' 'gato' 'perro' 'ratón' 'gato'\n 'elefante' 'elefante' 'elefante' 'elefante' 'perro' 'elefante' 'elefante'\n 'gato' 'ratón' 'perro' 'perro' 'gato' 'perro' 'perro' 'elefante' 'gato'\n 'perro' 'perro' 'perro' 'perro' 'gato' 'ratón' 'gato' 'gato' 'gato'\n 'perro' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'elefante' 'elefante'\n 'ratón' 'elefante' 'elefante' 'elefante' 'ratón' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'gato' 'gato' 'perro' 'elefante' 'elefante'\n 'elefante' 'ratón' 'perro' 'perro' 'gato' 'ratón' 'gato' 'perro' 'ratón'\n 'elefante' 'ratón' 'ratón' 'gato' 'ratón' 'gato' 'ratón' 'elefante'\n 'gato' 'gato' 'perro' 'elefante' 'perro' 'perro' 'gato' 'elefante'\n 'elefante' 'elefante' 'gato' 'perro' 'gato' 'perro' 'elefante' 'elefante'\n 'elefante' 'elefante' 'perro' 'gato' 'gato' 'elefante' 'ratón' 'perro'\n 'perro' 'ratón' 'ratón' 'perro' 'perro' 'elefante' 'elefante' 'perro'\n 'gato' 'perro' 'ratón' 'perro' 'ratón' 'gato' 'ratón' 'perro' 'elefante'\n 'gato' 'gato' 'ratón' 'ratón' 'perro' 'gato' 'ratón' 'ratón' 'perro'\n 'elefante' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'elefante' 'perro'\n 'ratón' 'perro' 'perro' 'perro' 'ratón' 'ratón' 'ratón' 'perro'\n 'elefante' 'perro' 'elefante' 'gato' 'elefante' 'elefante' 'elefante'\n 'elefante' 'ratón' 'elefante' 'ratón' 'elefante' 'perro' 'ratón' 'gato'\n 'elefante' 'perro' 'perro' 'ratón' 'perro' 'ratón' 'gato' 'gato' 'perro'\n 'gato' 'ratón' 'perro' 'elefante' 'gato' 'perro' 'gato' 'elefante'\n 'perro' 'ratón' 'gato' 'perro' 'elefante' 'elefante' 'gato' 'ratón'\n 'gato' 'elefante' 'perro' 'perro' 'ratón' 'gato' 'ratón' 'gato' 'perro'\n 'gato' 'perro' 'ratón' 'ratón' 'perro' 'ratón' 'gato' 'gato' 'ratón'\n 'ratón' 'gato' 'perro' 'elefante' 'elefante' 'gato' 'ratón' 'gato'\n 'ratón' 'gato' 'ratón' 'elefante' 'ratón' 'ratón' 'elefante' 'elefante'\n 'gato' 'elefante' 'ratón' 'elefante' 'perro' 'elefante' 'elefante'\n 'perro' 'gato' 'gato' 'elefante' 'perro' 'perro' 'perro' 'perro' 'gato'\n 'perro' 'ratón' 'ratón' 'gato' 'elefante' 'gato' 'gato' 'perro' 'ratón'\n 'perro' 'perro' 'elefante' 'ratón' 'ratón' 'gato' 'perro' 'perro'\n 'elefante' 'gato' 'perro' 'gato' 'gato' 'ratón' 'ratón' 'gato' 'perro'\n 'gato' 'ratón' 'perro' 'perro' 'ratón' 'gato' 'perro' 'perro' 'gato'\n 'gato' 'perro' 'elefante' 'ratón' 'ratón' 'perro' 'elefante' 'elefante'\n 'gato' 'ratón' 'elefante' 'perro' 'ratón' 'elefante' 'perro' 'perro'\n 'gato' 'elefante' 'elefante' 'elefante' 'ratón' 'perro' 'gato' 'gato'\n 'ratón' 'ratón' 'ratón' 'perro' 'elefante' 'gato' 'gato' 'gato' 'perro'\n 'elefante' 'gato' 'elefante' 'elefante' 'elefante' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'elefante' 'ratón' 'elefante' 'perro' 'ratón'\n 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'gato' 'ratón' 'perro' 'perro'\n 'ratón' 'gato' 'elefante' 'perro' 'gato' 'gato' 'ratón' 'elefante'\n 'ratón' 'ratón' 'ratón' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'ratón' 'perro' 'ratón' 'ratón' 'perro' 'perro' 'gato' 'perro' 'ratón'\n 'perro' 'elefante' 'ratón' 'elefante' 'gato' 'perro' 'gato' 'elefante'\n 'ratón' 'perro' 'perro' 'gato' 'perro' 'gato' 'gato' 'perro' 'gato'\n 'elefante' 'elefante' 'ratón' 'ratón' 'gato' 'gato' 'gato' 'perro'\n 'elefante' 'gato' 'ratón' 'elefante' 'elefante' 'ratón' 'ratón' 'perro'\n 'gato' 'gato' 'elefante' 'elefante' 'ratón' 'elefante' 'gato' 'ratón'\n 'gato' 'gato' 'ratón' 'perro' 'ratón' 'elefante' 'ratón' 'elefante'\n 'gato' 'gato' 'gato' 'gato' 'perro' 'gato' 'gato' 'ratón' 'perro'\n 'elefante' 'gato' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'elefante' 'ratón' 'perro' 'gato' 'perro' 'perro' 'perro' 'perro' 'gato'\n 'ratón' 'gato' 'elefante' 'perro' 'gato' 'perro' 'ratón' 'ratón' 'perro'\n 'elefante' 'elefante' 'elefante' 'perro' 'perro' 'ratón' 'perro' 'perro'\n 'ratón' 'ratón' 'ratón' 'gato' 'perro' 'gato' 'gato' 'ratón' 'ratón'\n 'gato' 'perro' 'gato' 'ratón' 'perro' 'perro' 'perro' 'ratón' 'ratón'\n 'ratón' 'elefante' 'gato' 'gato' 'elefante' 'gato' 'gato' 'ratón' 'ratón'\n 'ratón' 'perro' 'perro' 'elefante' 'elefante' 'elefante' 'elefante'\n 'elefante' 'perro' 'ratón' 'ratón' 'ratón' 'gato' 'ratón' 'gato' 'gato'\n 'elefante' 'elefante' 'elefante' 'perro' 'ratón' 'perro' 'perro' 'perro'\n 'gato' 'ratón' 'elefante' 'perro' 'elefante' 'elefante' 'elefante'\n 'elefante' 'elefante' 'perro' 'elefante' 'perro' 'ratón' 'elefante'\n 'elefante' 'perro' 'gato' 'ratón' 'ratón' 'elefante' 'elefante' 'gato'\n 'ratón' 'ratón' 'ratón' 'elefante' 'ratón' 'ratón' 'perro' 'perro'\n 'perro' 'elefante' 'elefante' 'elefante' 'gato' 'ratón' 'elefante'\n 'ratón' 'gato' 'perro' 'gato' 'elefante' 'gato' 'ratón' 'gato' 'gato'\n 'elefante' 'gato' 'gato' 'elefante' 'perro' 'perro' 'gato' 'perro' 'gato'\n 'ratón' 'gato' 'ratón' 'perro' 'perro' 'ratón' 'elefante' 'perro' 'perro'\n 'gato' 'perro' 'gato' 'perro' 'elefante' 'ratón' 'elefante' 'perro'\n 'perro' 'gato' 'perro' 'perro' 'gato' 'ratón' 'gato' 'gato' 'elefante'\n 'gato' 'perro' 'gato' 'gato' 'perro' 'gato' 'ratón' 'ratón' 'perro'\n 'gato' 'gato' 'elefante' 'ratón' 'perro' 'elefante' 'elefante' 'ratón'\n 'ratón' 'perro' 'gato' 'perro' 'ratón' 'gato' 'gato' 'perro' 'perro'\n 'perro' 'gato' 'perro' 'elefante' 'elefante' 'perro' 'perro' 'elefante'\n 'ratón' 'gato' 'ratón' 'gato' 'elefante' 'elefante' 'perro' 'ratón'\n 'gato' 'elefante' 'perro' 'perro' 'gato' 'gato' 'ratón' 'perro' 'perro'\n 'ratón' 'perro' 'ratón' 'gato' 'perro' 'elefante' 'ratón' 'ratón' 'perro'\n 'gato' 'perro' 'perro' 'perro' 'elefante' 'perro' 'gato' 'ratón' 'ratón'\n 'perro' 'ratón' 'gato' 'gato' 'ratón' 'perro' 'ratón' 'ratón' 'perro'\n 'elefante' 'gato' 'ratón' 'elefante' 'elefante' 'perro' 'gato' 'perro'\n 'perro' 'gato' 'ratón' 'perro' 'ratón' 'gato' 'ratón' 'elefante'\n 'elefante' 'perro' 'elefante' 'perro' 'gato' 'ratón' 'gato' 'perro'\n 'elefante' 'elefante' 'ratón' 'elefante' 'ratón' 'elefante' 'elefante'\n 'ratón' 'perro' 'perro' 'perro' 'elefante' 'ratón' 'gato' 'gato' 'gato'\n 'perro' 'elefante' 'elefante' 'elefante' 'gato' 'elefante' 'perro' 'gato'\n 'elefante' 'elefante' 'ratón' 'gato' 'gato' 'ratón' 'perro' 'elefante'\n 'perro' 'perro' 'perro' 'elefante' 'perro' 'perro' 'elefante' 'perro'\n 'elefante' 'gato' 'elefante' 'gato' 'gato' 'perro' 'gato' 'ratón'\n 'elefante' 'perro' 'perro' 'perro' 'elefante' 'perro' 'ratón' 'gato'\n 'elefante' 'gato' 'ratón' 'gato' 'gato' 'ratón' 'elefante' 'gato'\n 'elefante' 'elefante' 'gato' 'perro' 'gato' 'elefante' 'perro' 'ratón'\n 'elefante' 'elefante' 'elefante' 'elefante' 'perro' 'ratón' 'perro'\n 'ratón' 'gato' 'elefante' 'ratón' 'ratón' 'perro' 'elefante' 'ratón'\n 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'ratón' 'gato' 'gato'\n 'elefante' 'perro' 'elefante' 'perro' 'gato' 'perro' 'perro' 'perro'\n 'perro' 'ratón' 'ratón' 'gato' 'perro' 'gato' 'elefante' 'perro' 'ratón'\n 'perro' 'ratón' 'perro' 'gato' 'elefante' 'ratón' 'gato' 'perro' 'ratón'\n 'perro' 'elefante' 'gato' 'ratón' 'perro' 'elefante' 'ratón' 'ratón'\n 'ratón' 'perro' 'gato' 'gato' 'gato' 'perro' 'ratón' 'perro' 'ratón'\n 'elefante' 'perro' 'perro' 'ratón' 'elefante' 'ratón' 'elefante' 'ratón'\n 'gato' 'gato' 'gato' 'perro' 'elefante' 'gato' 'perro' 'gato' 'ratón'\n 'ratón' 'gato' 'elefante' 'gato' 'elefante' 'elefante' 'gato' 'ratón'\n 'ratón' 'ratón' 'gato' 'elefante' 'perro' 'perro' 'elefante' 'ratón'\n 'perro' 'elefante' 'ratón' 'gato' 'perro' 'ratón' 'gato' 'gato' 'ratón'\n 'ratón' 'gato' 'perro' 'perro' 'perro' 'elefante' 'gato' 'ratón' 'ratón'\n 'elefante' 'ratón' 'elefante' 'elefante' 'elefante'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "oh_codificador.fit(datos.col_categorica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que OneHotEncoder falla cuando se le pasan strings en vez de numeros. Por ello primero tenemos que convertir las variables categóricas a numéricas usando LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias_codificadas = label_codificador_categorico.transform(datos.col_categorica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, 1, 1, 2, 2, 2, 0, 0, 2, 0, 1, 3, 1, 3, 0, 3, 3, 0, 3, 3,\n",
       "       3, 1, 1, 3, 1, 0, 1, 0, 0, 0, 0, 3, 0, 1, 0, 1, 1, 1, 1, 3, 0, 1,\n",
       "       1, 2, 0, 1, 0, 2, 3, 2, 0, 3, 3, 1, 1, 0, 3, 2, 1, 1, 1, 1, 3, 0,\n",
       "       0, 2, 1, 3, 2, 0, 1, 1, 3, 3, 0, 2, 3, 3, 0, 1, 2, 3, 1, 0, 0, 2,\n",
       "       2, 2, 3, 1, 3, 1, 1, 0, 1, 1, 2, 2, 3, 2, 1, 0, 3, 2, 1, 1, 3, 1,\n",
       "       2, 2, 2, 1, 2, 2, 0, 2, 3, 1, 1, 1, 1, 3, 3, 3, 2, 0, 0, 2, 3, 1,\n",
       "       0, 1, 3, 3, 0, 1, 2, 3, 1, 0, 0, 0, 0, 2, 0, 0, 1, 3, 2, 2, 1, 2,\n",
       "       2, 0, 1, 2, 2, 2, 2, 1, 3, 1, 1, 1, 2, 3, 3, 0, 3, 3, 0, 0, 3, 0,\n",
       "       0, 0, 3, 3, 1, 2, 0, 0, 1, 1, 2, 0, 0, 0, 3, 2, 2, 1, 3, 1, 2, 3,\n",
       "       0, 3, 3, 1, 3, 1, 3, 0, 1, 1, 2, 0, 2, 2, 1, 0, 0, 0, 1, 2, 1, 2,\n",
       "       0, 0, 0, 0, 2, 1, 1, 0, 3, 2, 2, 3, 3, 2, 2, 0, 0, 2, 1, 2, 3, 2,\n",
       "       3, 1, 3, 2, 0, 1, 1, 3, 3, 2, 1, 3, 3, 2, 0, 1, 3, 2, 0, 3, 0, 2,\n",
       "       3, 2, 2, 2, 3, 3, 3, 2, 0, 2, 0, 1, 0, 0, 0, 0, 3, 0, 3, 0, 2, 3,\n",
       "       1, 0, 2, 2, 3, 2, 3, 1, 1, 2, 1, 3, 2, 0, 1, 2, 1, 0, 2, 3, 1, 2,\n",
       "       0, 0, 1, 3, 1, 0, 2, 2, 3, 1, 3, 1, 2, 1, 2, 3, 3, 2, 3, 1, 1, 3,\n",
       "       3, 1, 2, 0, 0, 1, 3, 1, 3, 1, 3, 0, 3, 3, 0, 0, 1, 0, 3, 0, 2, 0,\n",
       "       0, 2, 1, 1, 0, 2, 2, 2, 2, 1, 2, 3, 3, 1, 0, 1, 1, 2, 3, 2, 2, 0,\n",
       "       3, 3, 1, 2, 2, 0, 1, 2, 1, 1, 3, 3, 1, 2, 1, 3, 2, 2, 3, 1, 2, 2,\n",
       "       1, 1, 2, 0, 3, 3, 2, 0, 0, 1, 3, 0, 2, 3, 0, 2, 2, 1, 0, 0, 0, 3,\n",
       "       2, 1, 1, 3, 3, 3, 2, 0, 1, 1, 1, 2, 0, 1, 0, 0, 0, 3, 1, 2, 0, 0,\n",
       "       0, 3, 0, 2, 3, 3, 3, 0, 3, 3, 1, 3, 2, 2, 3, 1, 0, 2, 1, 1, 3, 0,\n",
       "       3, 3, 3, 1, 3, 2, 0, 3, 3, 3, 2, 3, 3, 2, 2, 1, 2, 3, 2, 0, 3, 0,\n",
       "       1, 2, 1, 0, 3, 2, 2, 1, 2, 1, 1, 2, 1, 0, 0, 3, 3, 1, 1, 1, 2, 0,\n",
       "       1, 3, 0, 0, 3, 3, 2, 1, 1, 0, 0, 3, 0, 1, 3, 1, 1, 3, 2, 3, 0, 3,\n",
       "       0, 1, 1, 1, 1, 2, 1, 1, 3, 2, 0, 1, 1, 3, 2, 0, 3, 3, 0, 3, 2, 1,\n",
       "       2, 2, 2, 2, 1, 3, 1, 0, 2, 1, 2, 3, 3, 2, 0, 0, 0, 2, 2, 3, 2, 2,\n",
       "       3, 3, 3, 1, 2, 1, 1, 3, 3, 1, 2, 1, 3, 2, 2, 2, 3, 3, 3, 0, 1, 1,\n",
       "       0, 1, 1, 3, 3, 3, 2, 2, 0, 0, 0, 0, 0, 2, 3, 3, 3, 1, 3, 1, 1, 0,\n",
       "       0, 0, 2, 3, 2, 2, 2, 1, 3, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 3, 0, 0,\n",
       "       2, 1, 3, 3, 0, 0, 1, 3, 3, 3, 0, 3, 3, 2, 2, 2, 0, 0, 0, 1, 3, 0,\n",
       "       3, 1, 2, 1, 0, 1, 3, 1, 1, 0, 1, 1, 0, 2, 2, 1, 2, 1, 3, 1, 3, 2,\n",
       "       2, 3, 0, 2, 2, 1, 2, 1, 2, 0, 3, 0, 2, 2, 1, 2, 2, 1, 3, 1, 1, 0,\n",
       "       1, 2, 1, 1, 2, 1, 3, 3, 2, 1, 1, 0, 3, 2, 0, 0, 3, 3, 2, 1, 2, 3,\n",
       "       1, 1, 2, 2, 2, 1, 2, 0, 0, 2, 2, 0, 3, 1, 3, 1, 0, 0, 2, 3, 1, 0,\n",
       "       2, 2, 1, 1, 3, 2, 2, 3, 2, 3, 1, 2, 0, 3, 3, 2, 1, 2, 2, 2, 0, 2,\n",
       "       1, 3, 3, 2, 3, 1, 1, 3, 2, 3, 3, 2, 0, 1, 3, 0, 0, 2, 1, 2, 2, 1,\n",
       "       3, 2, 3, 1, 3, 0, 0, 2, 0, 2, 1, 3, 1, 2, 0, 0, 3, 0, 3, 0, 0, 3,\n",
       "       2, 2, 2, 0, 3, 1, 1, 1, 2, 0, 0, 0, 1, 0, 2, 1, 0, 0, 3, 1, 1, 3,\n",
       "       2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 2, 1, 3, 0, 2, 2, 2,\n",
       "       0, 2, 3, 1, 0, 1, 3, 1, 1, 3, 0, 1, 0, 0, 1, 2, 1, 0, 2, 3, 0, 0,\n",
       "       0, 0, 2, 3, 2, 3, 1, 0, 3, 3, 2, 0, 3, 3, 2, 1, 0, 3, 3, 1, 1, 0,\n",
       "       2, 0, 2, 1, 2, 2, 2, 2, 3, 3, 1, 2, 1, 0, 2, 3, 2, 3, 2, 1, 0, 3,\n",
       "       1, 2, 3, 2, 0, 1, 3, 2, 0, 3, 3, 3, 2, 1, 1, 1, 2, 3, 2, 3, 0, 2,\n",
       "       2, 3, 0, 3, 0, 3, 1, 1, 1, 2, 0, 1, 2, 1, 3, 3, 1, 0, 1, 0, 0, 1,\n",
       "       3, 3, 3, 1, 0, 2, 2, 0, 3, 2, 0, 3, 1, 2, 3, 1, 1, 3, 3, 1, 2, 2,\n",
       "       2, 0, 1, 3, 3, 0, 3, 0, 0, 0])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorias_codificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorias_codificadas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x4 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorias_oh_codificadas = oh_codificador.fit_transform(categorias_codificadas.reshape(1000,1))\n",
    "categorias_oh_codificadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que por defecto `OneHotEncoder` no devuelve un numpy array, sino una matriz `sparse`. La traducción sería \"matriz escasa\", y es una manera de representar matrices con muchos ceros (como es el caso de OneHot encoding) para consumir poca memoria.\n",
    "\n",
    "Podemos convertir dichas matrices a arrays facilmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorias_oh_codificadas.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos ahora la comparación en memoria de una matriz sparse versus su correspondiente np.array usando la función `sys.getsizeof` que devuelve el uso de memoria un objeto de python en bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(categorias_oh_codificadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32112"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(categorias_oh_codificadas.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos que el encoder devuelva arrays no tenemos más que pasarle el parametro `sparse=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_codificador = preprocessing.OneHotEncoder(sparse=False)\n",
    "\n",
    "categorias_oh_codificadas = oh_codificador.fit_transform(categorias_codificadas.reshape(1000,1))\n",
    "categorias_oh_codificadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas tiene la funcion auxiliar `get_dummies` que hace esto automáticamente de forma más fácil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elefante</th>\n",
       "      <th>gato</th>\n",
       "      <th>perro</th>\n",
       "      <th>ratón</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   elefante  gato  perro  ratón\n",
       "0         0     0      0      1\n",
       "1         1     0      0      0\n",
       "2         0     0      0      1\n",
       "3         0     1      0      0\n",
       "4         0     1      0      0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(datos.col_categorica).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tenía en su casa una ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza, que así ensillaba el rocín como tomaba la podadera.',\n",
       "       'El resto della concluían sayo de velarte, calzas de velludo para las fiestas con sus pantuflos de lo mismo, los días de entre semana se honraba con su vellori de lo más fino.',\n",
       "       'El resto della concluían sayo de velarte, calzas de velludo para las fiestas con sus pantuflos de lo mismo, los días de entre semana se honraba con su vellori de lo más fino.',\n",
       "       'Una olla de algo más vaca que carnero, salpicón las más noches, duelos y quebrantos los sábados, lentejas los viernes, algún palomino de añadidura los domingos, consumían las tres partes de su hacienda.',\n",
       "       'Tenía en su casa una ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza, que así ensillaba el rocín como tomaba la podadera.',\n",
       "       'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua, rocín flaco y galgo corredor.',\n",
       "       'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua, rocín flaco y galgo corredor.',\n",
       "       'El resto della concluían sayo de velarte, calzas de velludo para las fiestas con sus pantuflos de lo mismo, los días de entre semana se honraba con su vellori de lo más fino.',\n",
       "       'Tenía en su casa una ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza, que así ensillaba el rocín como tomaba la podadera.',\n",
       "       'En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua, rocín flaco y galgo corredor.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.col_texto.values[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para convertir texto en variables numéricas, podemos proceder de igual forma que con las variables categóricas, simplemente separando las palabras antes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello tenemos dos vectorizadores en scikit-learn, que convierten texto en vectores.\n",
    "\n",
    "\n",
    "[CountVectorizer]() devuelve un vector con el valor 0 en todas las palabras que no existen en una frase y con el numero de ocurrencias de las palabras que si existen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer un ejemplo para que se vea bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 15 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo_frases = ['los coches rojos',\n",
    "          'los aviones son rojos',\n",
    "          'los coches y los aviones son rojos',\n",
    "          'los camiones rojos'\n",
    "                 ]\n",
    "\n",
    "\n",
    "vectorizador_count = feature_extraction.text.CountVectorizer()\n",
    "X = vectorizador_count.fit_transform(ejemplo_frases)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aviones', 'camiones', 'coches', 'los', 'rojos', 'son']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador_count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aviones</th>\n",
       "      <th>camiones</th>\n",
       "      <th>coches</th>\n",
       "      <th>los</th>\n",
       "      <th>rojos</th>\n",
       "      <th>son</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aviones  camiones  coches  los  rojos  son\n",
       "0        0         0       1    1      1    0\n",
       "1        1         0       0    1      1    1\n",
       "2        1         0       1    2      1    1\n",
       "3        0         1       0    1      1    0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X.toarray(), columns=vectorizador_count.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tomar simplemente el número de veces que aparece cada palabra tiene un problema, y es que da un mayor peso a aquellas palabras que aparecen muchas veces pero que no aportan ningun valor semántico (por ejemplo, `los`). Una manera más sofisticada de vectorizar un texto es en vez de usar el número de apariciones, usar TF-IDF. TF-IDF se traduce como Frecuencia de Texto - Frecuencia Inversa de Documento, y es una medida que asigna pesos a cada palabra en función de su frecuencia de aparición en todos los documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aviones</th>\n",
       "      <th>camiones</th>\n",
       "      <th>coches</th>\n",
       "      <th>los</th>\n",
       "      <th>rojos</th>\n",
       "      <th>son</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730064</td>\n",
       "      <td>0.483222</td>\n",
       "      <td>0.483222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.589645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.390280</td>\n",
       "      <td>0.390280</td>\n",
       "      <td>0.589645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.438931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.438931</td>\n",
       "      <td>0.581047</td>\n",
       "      <td>0.290524</td>\n",
       "      <td>0.438931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419880</td>\n",
       "      <td>0.419880</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    aviones  camiones    coches       los     rojos       son\n",
       "0  0.000000  0.000000  0.730064  0.483222  0.483222  0.000000\n",
       "1  0.589645  0.000000  0.000000  0.390280  0.390280  0.589645\n",
       "2  0.438931  0.000000  0.438931  0.581047  0.290524  0.438931\n",
       "3  0.000000  0.804612  0.000000  0.419880  0.419880  0.000000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador_tfidf = feature_extraction.text.TfidfVectorizer()\n",
    "X = vectorizador_tfidf.fit_transform(ejemplo_frases)\n",
    "pd.DataFrame(X.toarray(), columns=vectorizador_tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x134 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 28295 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador_tfidf = feature_extraction.text.TfidfVectorizer()\n",
    "texto_vectorizado = vectorizador_tfidf.fit_transform(datos.col_texto)\n",
    "texto_vectorizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.19788701, 0.19788701, 0.        , ..., 0.        , 0.        ,\n",
       "        0.19788701],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_vectorizado = texto_vectorizado.toarray()\n",
    "texto_vectorizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bien', 'mal', 'muy bien', 'muy mal', 'regular'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_codificador.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Poniendolo todo junto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp master\\.conda\\envs\\scidata\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "col_numericas =  ['col_inexistente1', 'col2', 'col3', 'col_outliers', 'col_outliers2']\n",
    "col_categorica = ['col_categorica']\n",
    "col_texto = ['col_texto']\n",
    "\n",
    "\n",
    "#Variables numéricas\n",
    "imputador = SimpleImputer(missing_values=np.nan, copy=False, strategy=\"mean\")\n",
    "escalador = preprocessing.StandardScaler()\n",
    "var_numericas_imputadas_escalado_standard = escalador.fit_transform(\n",
    "                                                imputador.fit_transform(datos[col_numericas])\n",
    "                                            )\n",
    "df_numerico_procesado = pd.DataFrame(var_numericas_imputadas_escalado_standard,\n",
    "                                                   columns=col_numericas)\n",
    "\n",
    "\n",
    "# Variable categorica\n",
    "label_codificador_categorico = preprocessing.LabelEncoder()\n",
    "categorias_codificadas = label_codificador_categorico.fit_transform(datos[col_categorica])\n",
    "oh_codificador = preprocessing.OneHotEncoder(sparse=False)\n",
    "categorias_oh_codificadas = oh_codificador.fit_transform(categorias_codificadas.reshape(1000,1))\n",
    "\n",
    "df_categorico_procesado = pd.DataFrame(categorias_oh_codificadas, \n",
    "                                       columns=label_codificador_categorico.classes_)\n",
    "\n",
    "\n",
    "# Texto\n",
    "vectorizador_tfidf = feature_extraction.text.TfidfVectorizer()\n",
    "texto_vectorizado = vectorizador_tfidf.fit_transform(datos.col_texto)\n",
    "df_texto_procesado =  pd.DataFrame(texto_vectorizado.toarray(), columns=vectorizador_tfidf.get_feature_names())\n",
    "\n",
    "\n",
    "datos_procesados = pd.concat([\n",
    "    df_numerico_procesado,\n",
    "    df_categorico_procesado,\n",
    "    df_texto_procesado \n",
    "], axis=1)\n",
    "\n",
    "# variable ordinal\n",
    "label_codificador_ordinal = preprocessing.LabelEncoder()\n",
    "datos_procesados['col_ordinal'] = label_codificador_ordinal.fit_transform(datos.col_ordinal) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers</th>\n",
       "      <th>col_outliers2</th>\n",
       "      <th>elefante</th>\n",
       "      <th>gato</th>\n",
       "      <th>perro</th>\n",
       "      <th>ratón</th>\n",
       "      <th>acordarme</th>\n",
       "      <th>...</th>\n",
       "      <th>vaca</th>\n",
       "      <th>veinte</th>\n",
       "      <th>velarte</th>\n",
       "      <th>vellori</th>\n",
       "      <th>velludo</th>\n",
       "      <th>verdad</th>\n",
       "      <th>verosímiles</th>\n",
       "      <th>viernes</th>\n",
       "      <th>vivía</th>\n",
       "      <th>col_ordinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.399217</td>\n",
       "      <td>0.082807</td>\n",
       "      <td>0.442819</td>\n",
       "      <td>-0.694600</td>\n",
       "      <td>-0.038365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.653605</td>\n",
       "      <td>0.861333</td>\n",
       "      <td>-0.323390</td>\n",
       "      <td>-0.118466</td>\n",
       "      <td>-0.038278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.226435</td>\n",
       "      <td>-0.766494</td>\n",
       "      <td>-0.484752</td>\n",
       "      <td>-0.464146</td>\n",
       "      <td>-0.038343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.540803</td>\n",
       "      <td>-1.191145</td>\n",
       "      <td>-0.375028</td>\n",
       "      <td>-1.129901</td>\n",
       "      <td>-0.038405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.194272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.616004</td>\n",
       "      <td>-0.766494</td>\n",
       "      <td>-0.516874</td>\n",
       "      <td>0.777743</td>\n",
       "      <td>-0.037257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.376838</td>\n",
       "      <td>0.365907</td>\n",
       "      <td>0.492254</td>\n",
       "      <td>0.611304</td>\n",
       "      <td>-0.038492</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.352799</td>\n",
       "      <td>-1.615795</td>\n",
       "      <td>0.131503</td>\n",
       "      <td>0.700925</td>\n",
       "      <td>-0.037878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-1.104815</td>\n",
       "      <td>0.118194</td>\n",
       "      <td>-0.420944</td>\n",
       "      <td>0.880166</td>\n",
       "      <td>-0.038197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.489641</td>\n",
       "      <td>1.569084</td>\n",
       "      <td>-0.407745</td>\n",
       "      <td>0.816152</td>\n",
       "      <td>-0.038190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.715245</td>\n",
       "      <td>0.224357</td>\n",
       "      <td>-0.136388</td>\n",
       "      <td>0.726531</td>\n",
       "      <td>-0.038315</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     col_inexistente1      col2      col3  col_outliers  col_outliers2  \\\n",
       "0            0.399217  0.082807  0.442819     -0.694600      -0.038365   \n",
       "1           -0.653605  0.861333 -0.323390     -0.118466      -0.038278   \n",
       "2            1.226435 -0.766494 -0.484752     -0.464146      -0.038343   \n",
       "3           -0.540803 -1.191145 -0.375028     -1.129901      -0.038405   \n",
       "4           -0.616004 -0.766494 -0.516874      0.777743      -0.037257   \n",
       "..                ...       ...       ...           ...            ...   \n",
       "995          1.376838  0.365907  0.492254      0.611304      -0.038492   \n",
       "996         -0.352799 -1.615795  0.131503      0.700925      -0.037878   \n",
       "997         -1.104815  0.118194 -0.420944      0.880166      -0.038197   \n",
       "998          1.489641  1.569084 -0.407745      0.816152      -0.038190   \n",
       "999          1.715245  0.224357 -0.136388      0.726531      -0.038315   \n",
       "\n",
       "     elefante  gato  perro  ratón  acordarme  ...      vaca    veinte  \\\n",
       "0         0.0   0.0    0.0    1.0   0.000000  ...  0.000000  0.204745   \n",
       "1         1.0   0.0    0.0    0.0   0.000000  ...  0.000000  0.000000   \n",
       "2         0.0   0.0    0.0    1.0   0.000000  ...  0.000000  0.000000   \n",
       "3         0.0   1.0    0.0    0.0   0.000000  ...  0.194272  0.000000   \n",
       "4         0.0   1.0    0.0    0.0   0.000000  ...  0.000000  0.204745   \n",
       "..        ...   ...    ...    ...        ...  ...       ...       ...   \n",
       "995       1.0   0.0    0.0    0.0   0.000000  ...  0.000000  0.000000   \n",
       "996       0.0   0.0    0.0    1.0   0.000000  ...  0.000000  0.204745   \n",
       "997       1.0   0.0    0.0    0.0   0.000000  ...  0.000000  0.000000   \n",
       "998       1.0   0.0    0.0    0.0   0.197887  ...  0.000000  0.000000   \n",
       "999       1.0   0.0    0.0    0.0   0.000000  ...  0.000000  0.204745   \n",
       "\n",
       "      velarte   vellori   velludo  verdad  verosímiles   viernes     vivía  \\\n",
       "0    0.000000  0.000000  0.000000     0.0          0.0  0.000000  0.000000   \n",
       "1    0.181842  0.181842  0.181842     0.0          0.0  0.000000  0.000000   \n",
       "2    0.181842  0.181842  0.181842     0.0          0.0  0.000000  0.000000   \n",
       "3    0.000000  0.000000  0.000000     0.0          0.0  0.194272  0.000000   \n",
       "4    0.000000  0.000000  0.000000     0.0          0.0  0.000000  0.000000   \n",
       "..        ...       ...       ...     ...          ...       ...       ...   \n",
       "995  0.000000  0.000000  0.000000     0.0          0.0  0.000000  0.000000   \n",
       "996  0.000000  0.000000  0.000000     0.0          0.0  0.000000  0.000000   \n",
       "997  0.181842  0.181842  0.181842     0.0          0.0  0.000000  0.000000   \n",
       "998  0.000000  0.000000  0.000000     0.0          0.0  0.000000  0.197887   \n",
       "999  0.000000  0.000000  0.000000     0.0          0.0  0.000000  0.000000   \n",
       "\n",
       "     col_ordinal  \n",
       "0              2  \n",
       "1              4  \n",
       "2              3  \n",
       "3              1  \n",
       "4              0  \n",
       "..           ...  \n",
       "995            3  \n",
       "996            2  \n",
       "997            4  \n",
       "998            0  \n",
       "999            4  \n",
       "\n",
       "[1000 rows x 144 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_procesados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
